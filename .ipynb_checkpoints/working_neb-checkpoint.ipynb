{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, re\n",
    "import copy\n",
    "from bvse_cal import bv_calculation\n",
    "from pymatgen.io.cif import CifWriter\n",
    "\n",
    "from monty.io import zopen\n",
    "\n",
    "from pymatgen.io.cif import CifParser\n",
    "from pymatgen.transformations.standard_transformations import OrderDisorderedStructureTransformation\n",
    "from pymatgen.transformations.standard_transformations import DiscretizeOccupanciesTransformation\n",
    "from pymatgen.transformations.standard_transformations import ConventionalCellTransformation\n",
    "from pymatgen.analysis.structure_matcher import StructureMatcher\n",
    "from pymatgen import symmetry\n",
    "from pymatgen import Structure\n",
    "import pymatgen.io.ase as ase_io\n",
    "import pymatgen.io.cif as cif_io\n",
    "\n",
    "from ase.build import bulk\n",
    "from ase.io import espresso\n",
    "import ase.io\n",
    "\n",
    "import Structure as customstruc\n",
    "import BVAnalysis\n",
    "\n",
    "import matplotlib as mpl\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "import itertools\n",
    "from collections import OrderedDict\n",
    "import pwscf_input\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import json\n",
    "\n",
    "import pymatgen.core.periodic_table as pt\n",
    "\n",
    "from multiprocessing import Pool\n",
    "from functools import partial\n",
    "import worker_neb_bvse\n",
    "\n",
    "from cavd.netio import *\n",
    "from cavd.channel import Channel\n",
    "from cavd.netstorage import AtomNetwork, connection_values_list\n",
    "from cavd.local_environment import CifParser_new, LocalEnvirCom\n",
    "from cavd.get_Symmetry import get_symnum_sites, get_equivalent_vornet,get_labeled_vornet\n",
    "from cavd.recovery import rediscovery, rediscovery_kdTree, rediscovery_byRad_kdTree, rediscovery_byRad_kdTree_onlyVertex\n",
    "from cavd import bmd_com\n",
    "from cavd_bvse.mergecluster import load_voids_channels_from_file, load_struc, load_bvse\n",
    "\n",
    "from cavd_bvse.non_equivalent_paths import non_equivalent_paths\n",
    "\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NEB Calculations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section describes the process for generating input files for NEB calculations based on initial pathways determined by the CAVD + BVSE pipeline. If NEB calculations are required for an initial pathway not included in the output from CAVD+BVSE (outMEP), some steps may be needed to be performed manually."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating SCF input files to perform convergence testing on nominal unit cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_qe_scf(cif_filename, ecutwfc, ecutrho, kpoints, transport_ion):\n",
    "\n",
    "    filepath = os.path.join(os.getcwd(), transport_ion + '_NEB_Cifs/' + cif_filename)\n",
    "    structureName = cif_filename.replace(\".cif\", \"\")\n",
    "\n",
    "    # Create QE Input classes\n",
    "    scf_input = pwscf_input.PWscfInput(ase.io.read(filepath))\n",
    "\n",
    "    # Set directory that contains pseudopotentials for relevant species\n",
    "    pseudo_dir = '/central/groups/SeeGroup/qe_pseudopotentials/'\n",
    "    scf_input.control.settings.pseudo_dir = pseudo_dir\n",
    "\n",
    "    # Set mass and pseudo potential file for each specie type\n",
    "    mass_table = pd.read_table(os.path.join(os.getcwd(), 'elements.dat'), index_col=0, names=['Elements', 'Mass'],\n",
    "                               usecols=[1, 4]).drop_duplicates()\n",
    "\n",
    "    for root, dirs, files in os.walk(os.path.join(os.getcwd(), 'pseudopotentials')):\n",
    "        pseudo_files = files\n",
    "\n",
    "    sorted_pseudo_files = []\n",
    "    for specie_num, specie in enumerate(scf_input.atomic_species.symbol):\n",
    "        pseudo_found = False\n",
    "        for pseudo in pseudo_files:\n",
    "            if pseudo.split('.')[0] == specie:\n",
    "                sorted_pseudo_files.append(pseudo)\n",
    "                pseudo_found = True\n",
    "        if not pseudo_found:\n",
    "            raise ValueError(\"A pseudopotential for {} was not found in the pseduo directory\".format(specie))\n",
    "        scf_input.atomic_species.mass[specie_num] = mass_table.loc[specie, 'Mass']\n",
    "    scf_input.atomic_species.pseudo_potential = np.array(sorted_pseudo_files)\n",
    "\n",
    "    # Set calculation to SCF\n",
    "    scf_input.control.settings.calculation = 'scf'\n",
    "\n",
    "    # Set desired ecutwfc, ecutrho, kpoints\n",
    "    # SHOULD EDIT THIS SO THAT DEFAULT IS THE VALUE SPECIFIED BY PSEUDOPOTENTIAL\n",
    "    scf_input.system.ecut.ecutwfc = ecutwfc\n",
    "    scf_input.system.ecut.ecutrho = ecutrho\n",
    "    scf_input.kpoints.nk = kpoints\n",
    "\n",
    "    # Write input file to ./SCF_inputs directory\n",
    "    scf_input.write_input(\n",
    "        './SCF_inputs/{}_ecutwfc{}ecutrho{}_k{}{}{}.in'.format(structureName, ecutwfc, ecutrho, kpoints[0],\n",
    "                                                                   kpoints[1], kpoints[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example usage of above code to create pw.x scf input files for Quantum ESPRESSO. Generating inputs for MgY2S4_mp-1001024.cif, with range of wave function cutoff values (40, 60, 80, 100, 120, 140, 160):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [40, 60, 80, 100, 120, 140, 160]:\n",
    "    create_qe_scf(\"MgY2S4_mp-1001024.cif\", i, i*5, [2, 2, 2], \"Mg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The files generated by the above code will be located in the \"SCF_inputs\" directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parsing SCF output files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_scf(out_filename):\n",
    "\n",
    "    with open(out_filename, \"rt\") as scf_file:\n",
    "        lines = [line for line in scf_file.readlines() if line.strip()]\n",
    "\n",
    "    scf_dic = {}\n",
    "\n",
    "    for line in lines:\n",
    "        split_line = line.split()\n",
    "        if split_line[0] == '!':\n",
    "            scf_dic['total_energy'] = line.split()[-2]\n",
    "        elif 'P=' in split_line:\n",
    "            scf_dic['total_pressure'] = line.split()[-1]\n",
    "        elif split_line[0] == 'kinetic-energy':\n",
    "            scf_dic['wfc_cutoff'] = split_line[-2]\n",
    "        elif split_line[0] == 'charge':\n",
    "            scf_dic['rho_cutoff'] = split_line[-2]\n",
    "        elif split_line[0:3] == ['number', 'of', 'k']:\n",
    "            scf_dic['ibz_kpoint'] = split_line[4]\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "    return scf_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scf_to_df():\n",
    "\n",
    "    root = tk.Tk()\n",
    "    root.withdraw()\n",
    "\n",
    "    filenames = filedialog.askopenfilenames()\n",
    "\n",
    "    scf_data_rows = []\n",
    "\n",
    "    for file in filenames:\n",
    "        scf_dic = parse_scf(file)\n",
    "        scf_data_rows.append(scf_dic)\n",
    "\n",
    "    scf_dataframe = pd.DataFrame(scf_data_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating vc-relax input file to relax nominal unit cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_qe_vcrelax(cif_filename, ecutwfc, ecutrho, kpoints, transport_ion):\n",
    "\n",
    "    filepath = os.path.join(os.getcwd(), transport_ion + '_NEB_Cifs/' + cif_filename)\n",
    "    structureName = cif_filename.replace(\".cif\", \"\")\n",
    "\n",
    "    # Create QE Input classes\n",
    "    vcrelax_input = pwscf_input.PWscfInput(ase.io.read(filepath))\n",
    "\n",
    "    # Set directory that contains pseudopotentials for relevant species\n",
    "    pseudo_dir = '/central/groups/SeeGroup/qe_pseudopotentials/'\n",
    "    vcrelax_input.control.settings.pseudo_dir = pseudo_dir\n",
    "\n",
    "    # Set mass and pseudo potential file for each specie type\n",
    "    mass_table = pd.read_table(os.path.join(os.getcwd(), 'elements.dat'), index_col=0, names=['Elements', 'Mass'],\n",
    "                               usecols=[1, 4]).drop_duplicates()\n",
    "\n",
    "    for root, dirs, files in os.walk(os.path.join(os.getcwd(), 'pseudopotentials')):\n",
    "        pseudo_files = files\n",
    "\n",
    "    sorted_pseudo_files = []\n",
    "    for specie_num, specie in enumerate(vcrelax_input.atomic_species.symbol):\n",
    "        for pseudo in pseudo_files:\n",
    "            if pseudo.startswith(specie):\n",
    "                sorted_pseudo_files.append(pseudo)\n",
    "        vcrelax_input.atomic_species.mass[specie_num] = mass_table.loc[specie, 'Mass']\n",
    "    vcrelax_input.atomic_species.pseudo_potential = np.array(sorted_pseudo_files)\n",
    "\n",
    "    # Set calculation to relax\n",
    "    vcrelax_input.control.settings.calculation = 'vc-relax'\n",
    "    vcrelax_input.control.settings.prefix = structureName + '_vc-relax'\n",
    "    vcrelax_input.control.ion_relax.etot_conv_thr = 1E-6\n",
    "    vcrelax_input.control.ion_relax.forc_conv_thr = 1E-5\n",
    "    \n",
    "    # Set desired ecutwfc, ecutrho, kpoints\n",
    "    # SHOULD EDIT THIS SO THAT DEFAULT IS THE VALUE SPECIFIED BY PSEUDOPOTENTIAL\n",
    "    vcrelax_input.system.ecut.ecutwfc = ecutwfc\n",
    "    vcrelax_input.system.ecut.ecutrho = ecutrho\n",
    "    vcrelax_input.kpoints.nk = kpoints\n",
    "\n",
    "    # Write input file to ./SCF_inputs directory\n",
    "    vcrelax_input.write_input(\n",
    "        './Relax_inputs/{}_ecutwfc{}ecutrho{}_k{}{}{}_vcrelax.in'.format(structureName, ecutwfc, ecutrho, kpoints[0],\n",
    "                                                                       kpoints[1], kpoints[2]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate cif file from vc-relax output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_espresso_structure(qe_filename, struc_index):\n",
    "\n",
    "    output_strucs = [struc for struc in espresso.read_espresso_out(qe_filename, slice(-1))]\n",
    "\n",
    "    ase_pymatgen_adapter = ase_io.AseAtomsAdaptor()\n",
    "\n",
    "    return ase_pymatgen_adapter.get_structure(output_strucs[struc_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vcr_to_cif(qe_filename, struc_index=-1):\n",
    "\n",
    "    struc = get_espresso_structure(qe_filename, struc_index)\n",
    "\n",
    "    species = struc.species\n",
    "    coords = struc.frac_coords\n",
    "\n",
    "    orig_lattice = struc.lattice.matrix\n",
    "    conversion = 0.529177249\n",
    "    lattice = orig_lattice * conversion\n",
    "\n",
    "    vcr_struc = Structure(lattice=lattice, species=species, coords=coords)\n",
    "    vcr_struc.to(\"cif\", os.path.join(os.path.dirname(qe_filename), struc.composition.reduced_formula + '_vcr' + '.cif'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example usage of above code for Li3ErBr6. Creating cif from vc_relax output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "qe_filename = r\"C:\\Users\\mchaf\\Documents\\Caltech\\Research\\Kims Group\\Calculations\\materials_discovery_project\\SPSE_codes\\spse\\bvs_v12012020\\HPC_work\\Li3ErBr6\\Li3ErBr6_mp-1222492_conventional_standard_ecutwfc120ecutrho600_k424_vcr_n48N2c1_nk2ndiag1.out\"\n",
    "vcr_to_cif(qe_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Right now, add oxidation info to cif manually"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run CAVD+BVSE analysis on computationally-relaxed unit cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create initial and final configurations for desired pathway with appropriate unit cell and shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_path_struc(filename):\n",
    "\n",
    "    # Get filepath to text file with path info\n",
    "    paths_filepath = os.path.join(os.getcwd(), 'non_equivalent_paths_outputs/' + filename + \"_nonequalpaths.txt\")\n",
    "\n",
    "    # Get filepath to corresponding cif file\n",
    "    cif_filepath = os.path.join(os.getcwd(), 'non_equivalent_paths_outputs/' + filename + \"_mepstructure.cif\")\n",
    "\n",
    "    # Read path file and put info into dictionary\n",
    "    paths_dic = {}\n",
    "    with open(paths_filepath, \"rt\") as paths_file:\n",
    "        for line in paths_file.read().splitlines()[:-1]:\n",
    "            if line.split()[0] == \"nonequalpath\":\n",
    "                temp_pathid = line.split()[1].split(\":\")[-1]\n",
    "                paths_dic[temp_pathid] = []\n",
    "            else:\n",
    "                paths_dic[temp_pathid].append([float(i) for i in line.split()[1:]])\n",
    "\n",
    "    for path in paths_dic:\n",
    "        paths_dic[path] = np.array(paths_dic[path])\n",
    "\n",
    "    #  Sort paths by increasing activation energy (max - min energy along path)\n",
    "    sorted_paths = {key: paths_dic[key] for key in sorted(paths_dic, key=lambda x: abs(max(paths_dic[x][:, -1]) -\n",
    "                                                                                       min(paths_dic[x][:, -1])))}\n",
    "    # Parse cif file and create structure. Pymatgen Structure method \"from_file\" is being used instead of CifParser as\n",
    "    # the former does not change order of lattice constants or symmetry\n",
    "    struc = Structure.from_file(cif_filepath)\n",
    "\n",
    "    return sorted_paths, struc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_closest_ions(sorted_paths, struc, des_path, transport_ion, supercell=None, shift=None):\n",
    "\n",
    "    species = [str(sp).replace(\"Specie \", \"\") for sp in struc.species if sp.element.value != transport_ion]\n",
    "\n",
    "    start_path_coords_frac = sorted_paths[str(des_path)][2, :-2]\n",
    "    end_path_coords_frac = sorted_paths[str(des_path)][-3, :-2]\n",
    "\n",
    "    for i in range(3):\n",
    "        if start_path_coords_frac[i] < 0.0:\n",
    "            start_path_coords_frac[i] += 1\n",
    "        elif start_path_coords_frac[i] > 1.0:\n",
    "            start_path_coords_frac[i] -= 1\n",
    "        else:\n",
    "            continue\n",
    "        if end_path_coords_frac[i] < 0.0:\n",
    "            end_path_coords_frac[i] += 1\n",
    "        elif end_path_coords_frac[i] > 1.0:\n",
    "            end_path_coords_frac[i] -= 1\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "    temp_struc_initial = Structure(struc.lattice, struc.species, struc.frac_coords)\n",
    "    temp_struc_final = Structure(struc.lattice, struc.species, struc.frac_coords)\n",
    "\n",
    "    for specie in struc.types_of_specie:\n",
    "        if specie.element.value == transport_ion:\n",
    "            des_specie = specie\n",
    "\n",
    "    if supercell:\n",
    "        print('Using supercell: ', supercell)\n",
    "        temp_struc_initial.make_supercell(supercell)\n",
    "        temp_struc_final.make_supercell(supercell)\n",
    "        if shift:\n",
    "            print('Using shift: ', shift)\n",
    "            start_path_coords_frac = (start_path_coords_frac + shift) / supercell\n",
    "            end_path_coords_frac = (end_path_coords_frac + shift) / supercell\n",
    "        else:\n",
    "            start_path_coords_frac = start_path_coords_frac / supercell\n",
    "            end_path_coords_frac = end_path_coords_frac / supercell\n",
    "\n",
    "    temp_struc_initial.remove_species(species)\n",
    "    temp_struc_initial.append(species=des_specie, coords=start_path_coords_frac, coords_are_cartesian=False)\n",
    "    distances = temp_struc_initial.distance_matrix + np.identity(temp_struc_initial.num_sites) * 100\n",
    "    start_closest_ion = np.argmin(distances[:, -1])\n",
    "\n",
    "    temp_struc_final.remove_species(species)\n",
    "    temp_struc_final.append(species=des_specie, coords=end_path_coords_frac, coords_are_cartesian=False)\n",
    "    distances = temp_struc_final.distance_matrix + np.identity(temp_struc_final.num_sites) * 100\n",
    "    end_closest_ion = np.argmin(distances[:, -1])\n",
    "\n",
    "    return start_closest_ion, end_closest_ion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_boundary_structures(filename, des_path, transport_ion, supercell=None, shift=None):\n",
    "\n",
    "        # WILL NEED TO CONSIDER CASES WHERE PATH EXTENDS OUTSIDE CELL\n",
    "\n",
    "    # Grab structure\n",
    "    sorted_paths, struc = parse_path_struc(filename)\n",
    "\n",
    "    # Find closest ions\n",
    "    start_ion, end_ion = findCLOSESTIONS(sorted_paths, struc, des_path, transport_ion, supercell=supercell, shift=shift)\n",
    "\n",
    "    # Finding first instance of transport ion to have correct site numbering for later removal\n",
    "    site_offset = [specie.element.value for specie in struc.species].index(transport_ion)\n",
    "\n",
    "    # Make a supercell\n",
    "    if supercell:\n",
    "        struc.make_supercell(supercell)\n",
    "        supercell_label = 'supercell' + ''.join([str(i) for i in supercell])\n",
    "    else:\n",
    "        supercell_label = ''\n",
    "\n",
    "    if shift:\n",
    "        shift_label = 'shift' + ''.join([str(i) for i in shift])\n",
    "    else:\n",
    "        shift_label = ''\n",
    "\n",
    "    # Create two temporary structures. One with the start_ion removed and the other with the end_ion removed.\n",
    "    init_struct = copy.deepcopy(struc)\n",
    "    final_struct = copy.deepcopy(struc)\n",
    "\n",
    "    init_struct.remove_sites([start_ion + site_offset])\n",
    "    final_struct.remove_sites([end_ion + site_offset])\n",
    "\n",
    "    # Use these structures to create SCF input files. Might need to write to cif first. Either with Pymatgen or ASE.\n",
    "    init_struct_writer = CifWriter(init_struct)\n",
    "    init_struct_cif_filename = './' + transport_ion + '_NEB_Cifs/' + struc.composition.reduced_formula + \"_initstruct_path\" + str(des_path) + supercell_label + shift_label + '.cif'\n",
    "    init_struct_writer.write_file(init_struct_cif_filename)\n",
    "\n",
    "    final_struct_cif_filename = './' + transport_ion +'_NEB_Cifs/' + struc.composition.reduced_formula + \"_finalstruct_path\" + str(des_path) + supercell_label + shift_label +'.cif'\n",
    "    final_struct_writer = CifWriter(final_struct)\n",
    "    final_struct_writer.write_file(final_struct_cif_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example usage of above code for Li3ErBr6. Making boundary configurations of 212 supercell with shift of 000 (no shift)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using supercell:  [2, 1, 2]\n",
      "Using shift:  [0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "create_boundary_structures(\"Li3ERBr6_vcr\", 6, \"Li\", supercell=[2,1,2], shift=[0,0,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create SCF input files to perform k-mesh convergence testing on initial and final configurations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create input files for relaxation using the initial and final configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_qe_relax(cif_filename, ecutwfc, ecutrho, kpoints, transport_ion):\n",
    "\n",
    "    filepath = os.path.join(os.getcwd(), transport_ion + '_NEB_Cifs/' + cif_filename)\n",
    "    structureName = cif_filename.replace(\".cif\", \"\")\n",
    "\n",
    "    # Create QE Input classes\n",
    "    relax_input = pwscf_input.PWscfInput(ase.io.read(filepath))\n",
    "\n",
    "    # Set directory that contains pseudopotentials for relevant species\n",
    "    pseudo_dir = '/central/groups/SeeGroup/qe_pseudopotentials/'\n",
    "    relax_input.control.settings.pseudo_dir = pseudo_dir\n",
    "\n",
    "    # Set mass and pseudo potential file for each specie type\n",
    "    mass_table = pd.read_table(os.path.join(os.getcwd(), 'elements.dat'), index_col=0, names=['Elements', 'Mass'],\n",
    "                               usecols=[1, 4]).drop_duplicates()\n",
    "\n",
    "    for root, dirs, files in os.walk(os.path.join(os.getcwd(), 'pseudopotentials')):\n",
    "        pseudo_files = files\n",
    "\n",
    "    sorted_pseudo_files = []\n",
    "    for specie_num, specie in enumerate(relax_input.atomic_species.symbol):\n",
    "        for pseudo in pseudo_files:\n",
    "            if pseudo.startswith(specie):\n",
    "                sorted_pseudo_files.append(pseudo)\n",
    "        relax_input.atomic_species.mass[specie_num] = mass_table.loc[specie, 'Mass']\n",
    "    relax_input.atomic_species.pseudo_potential = np.array(sorted_pseudo_files)\n",
    "\n",
    "    relax_input.control.settings.prefix = structureName + '_relax'\n",
    "\n",
    "    # Set calculation to relax\n",
    "    relax_input.control.settings.calculation = 'relax'\n",
    "\n",
    "    relax_input.control.ion_relax.etot_conv_thr = 1E-6\n",
    "    relax_input.control.ion_relax.forc_conv_thr = 1E-5\n",
    "\n",
    "    # REMOVING SYMMETRY FOR NEB CALCULATIONS BY DEFAULT\n",
    "    relax_input.system.occupations.nosym = \".true\"\n",
    "\n",
    "    # Set desired ecutwfc, ecutrho, kpoints\n",
    "    # SHOULD EDIT THIS SO THAT DEFAULT IS THE VALUE SPECIFIED BY PSEUDOPOTENTIAL\n",
    "    relax_input.system.ecut.ecutwfc = ecutwfc\n",
    "    relax_input.system.ecut.ecutrho = ecutrho\n",
    "    relax_input.kpoints.nk = kpoints\n",
    "\n",
    "    # Write input file to ./SCF_inputs directory\n",
    "    relax_input.write_input(\n",
    "        './Relax_inputs/{}_ecutwfc{}ecutrho{}_k{}{}{}_RELAX.in'.format(structureName, ecutwfc, ecutrho, kpoints[0],\n",
    "                                                                   kpoints[1], kpoints[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run relaxation on initial and final configurations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate NEB images with initial and final configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_neb_images(outmep_filename, init_relax_filename, final_relax_filename, des_path, transport_ion, num_images,\n",
    "                    supercell=None, shift=None):\n",
    "\n",
    "    # Take care when using this function. If the relaxed structure is a supercell of the structure with the MEP\n",
    "    # information, the supercell parameter must be set. Similarly, if the path was shifted when the boundary\n",
    "    # configurations of the relaxed structures were created, the shift parameter must be set to match\n",
    "\n",
    "    # parse path information from outMEP\n",
    "    sorted_paths, orig_struc = parse_path_struc(outmep_filename)\n",
    "\n",
    "    # parse structures from initial and final state relaxation calculations\n",
    "    init_relax_filepath = \"./Relaxed_Configs/\" + init_relax_filename\n",
    "    final_relax_filepath = \"./Relaxed_Configs/\" + final_relax_filename\n",
    "\n",
    "    initial_relaxed_struc = get_espresso_structure(init_relax_filepath, -1)\n",
    "    final_relaxed_struc = get_espresso_structure(final_relax_filepath, -1)\n",
    "\n",
    "    # Find final ion position (init struc) and initial ion position (final struc)\n",
    "    _, init_struc_endion = findCLOSESTIONSNEB(sorted_paths, orig_struc, initial_relaxed_struc, des_path, transport_ion,\n",
    "                                              supercell=supercell, shift=shift)\n",
    "    final_struc_startion, _ = findCLOSESTIONSNEB(sorted_paths, orig_struc, final_relaxed_struc, des_path, transport_ion,\n",
    "                                                 supercell=supercell, shift=shift)\n",
    "\n",
    "    # Finding first instance of transport ion to have correct site numbering for later removal\n",
    "    # MIGHT NOT WORK WITH SUPERCELLL\n",
    "    # DEFINITE POSSIBLE SOURCE OF ERROR!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "    init_site_offset = [element.value for element in initial_relaxed_struc.species].index(transport_ion)\n",
    "    final_site_offset = [element.value for element in final_relaxed_struc.species].index(transport_ion)\n",
    "\n",
    "    # Save coordinates for initial and final ion position\n",
    "    init_struc_endion_coords = initial_relaxed_struc.sites[init_struc_endion + init_site_offset].frac_coords\n",
    "    final_struc_startion_coords = final_relaxed_struc.sites[final_struc_startion + final_site_offset].frac_coords\n",
    "\n",
    "    # Remove initial and final ion\n",
    "    initial_relaxed_struc.remove_sites([init_struc_endion + init_site_offset])\n",
    "    final_relaxed_struc.remove_sites([final_struc_startion + final_site_offset])\n",
    "\n",
    "    # Interpolate structures from final to initial (this is to match ordering of path)\n",
    "    images = final_relaxed_struc.interpolate(initial_relaxed_struc, nimages=(num_images - 1))\n",
    "\n",
    "    # Interpolate nimage points along path\n",
    "    ion_path_frac_coords = sorted_paths[str(des_path)][\n",
    "                       np.round(np.linspace(0, len(sorted_paths[str(des_path)]) - 1, num_images)).astype(int), :-2]\n",
    "\n",
    "    for i in range(ion_path_frac_coords.shape[0]):\n",
    "        for j in range(ion_path_frac_coords.shape[1]):\n",
    "            if ion_path_frac_coords[i, j] < 0.0:\n",
    "                ion_path_frac_coords[i, j] += 1\n",
    "            if ion_path_frac_coords[i, j] > 1.0:\n",
    "                ion_path_frac_coords[i, j] -= 1\n",
    "\n",
    "    if supercell:\n",
    "        if shift:\n",
    "            print('Using shift: ', shift)\n",
    "            ion_path_frac_coords = (ion_path_frac_coords + shift) / supercell\n",
    "        else:\n",
    "            ion_path_frac_coords = ion_path_frac_coords / supercell\n",
    "\n",
    "\n",
    "    ion_path_frac_coords[0, :] = final_struc_startion_coords\n",
    "    ion_path_frac_coords[-1, :] = init_struc_endion_coords\n",
    "\n",
    "    for image_num, image in enumerate(images):\n",
    "        image.append(species=transport_ion, coords=ion_path_frac_coords[image_num], coords_are_cartesian=False)\n",
    "        \n",
    "    return images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example usage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = createNEBIMAGES(\"LiGaTe2_vcr\", \"LiGaTe2_initstruct_path3supercell221shift000_ecutwfc120ecutrho600_k222_RELAX_n48N2c1_nk2ndiag9.out\", \"LiGaTe2_finalstruct_path3supercell221shift000_ecutwfc120ecutrho600_k222_RELAX_n48N2c1_nk2ndiag9.out\", des_path=3, transport_ion=\"Li\", num_images=7, supercell=[2,2,1], shift=[0,0,0])\n",
    "\n",
    "for i in range(len(images)):\n",
    "    images[i].to(\"cif\", \"LiGaTe2_initstruct_path3supercell221shift000\" + str(i) + \".cif\")   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate NEB Input file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createQENEB(base_filename, ecutwfc, ecutrho, kpoints, num_images):\n",
    "\n",
    "    images_atomic_info = []\n",
    "    for i in range(num_images):\n",
    "        images_atomic_info.append(ase.io.read(base_filename + \"_image\" + str(i) + \".cif\"))\n",
    "\n",
    "    neb = neb_input.NEBINPUT(images_atomic_info)\n",
    "\n",
    "    # Set mass and pseudo potential file for each specie type\n",
    "    mass_table = pd.read_table(os.path.join(os.getcwd(), 'elements.dat'), index_col=0, names=['Elements', 'Mass'],\n",
    "                               usecols=[1, 4]).drop_duplicates()\n",
    "\n",
    "    for root, dirs, files in os.walk(os.path.join(os.getcwd(), 'pseudopotentials')):\n",
    "        pseudo_files = files\n",
    "\n",
    "    sorted_pseudo_files = []\n",
    "    for specie_num, specie in enumerate(neb.atomic_species.symbol):\n",
    "        for pseudo in pseudo_files:\n",
    "            if pseudo.startswith(specie):\n",
    "                sorted_pseudo_files.append(pseudo)\n",
    "        neb.atomic_species.mass[specie_num] = mass_table.loc[specie, 'Mass']\n",
    "    neb.atomic_species.pseudo_potential = np.array(sorted_pseudo_files)\n",
    "\n",
    "    neb.control.settings.prefix = base_filename + '_neb'\n",
    "\n",
    "    # REMOVING SYMMETRY FOR NEB CALCULATIONS BY DEFAULT\n",
    "    neb.system.occupations.nosym = True\n",
    "\n",
    "    # Set desired ecutwfc, ecutrho, kpoints\n",
    "    # SHOULD EDIT THIS SO THAT DEFAULT IS THE VALUE SPECIFIED BY PSEUDOPOTENTIAL\n",
    "    neb.system.ecut.ecutwfc = ecutwfc\n",
    "    neb.system.ecut.ecutrho = ecutrho\n",
    "    neb.kpoints.nk = kpoints\n",
    "\n",
    "    neb.write_input(\n",
    "        './SCF_inputs/{}_ecutwfc{}ecutrho{}_k{}{}{}.in'.format(base_filename, ecutwfc, ecutrho, kpoints[0],\n",
    "                                                                   kpoints[1], kpoints[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse NEB Output file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_neb(filename):\n",
    "    \n",
    "    with open(filename, \"rt\") as neb_file:\n",
    "        lines = [line for line in neb_file.readlines() if line.strip()]\n",
    "\n",
    "    neb_dic = {}\n",
    "    curr_iteration = []\n",
    "    for index, line in enumerate(lines):\n",
    "        curr_iteration.append(line)\n",
    "        if r'iteration' in line.split():\n",
    "            iteration_label = \"iteration\" + line.split()[2]\n",
    "            curr_iteration = []\n",
    "        if '     inter-image distance ' == line.split(\"=\")[0]:\n",
    "            iteration_dic = {}\n",
    "            for it_index, it_line in enumerate(curr_iteration):\n",
    "                if '(->)' in it_line.split():\n",
    "                    iteration_dic['forward_activation_energy'] = it_line.split()[-2]\n",
    "                elif '(<-)' in it_line.split():\n",
    "                    iteration_dic['backward_activation_energy'] = it_line.split()[-2]\n",
    "                elif it_line.split()[0] == 'image':\n",
    "                    image_count = 1\n",
    "                    init_image_energy = float(curr_iteration[it_index + image_count].split()[-3])\n",
    "                    while curr_iteration[it_index + image_count].split()[0].isnumeric():\n",
    "                        iteration_dic['image_' + str(image_count) + '_energy'] = float(\n",
    "                            curr_iteration[it_index + image_count].split()[-3]) - init_image_energy\n",
    "                        image_count += 1\n",
    "                    iteration_dic['path length'] = curr_iteration[it_index + image_count].split()[-2]\n",
    "                    iteration_dic['inter-image distance'] = curr_iteration[it_index + image_count + 1].split()[-2]\n",
    "                else:\n",
    "                    continue\n",
    "            neb_dic[iteration_label] = iteration_dic\n",
    "    return neb_dic"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
