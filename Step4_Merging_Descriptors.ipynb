{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import sys\n",
    "import re\n",
    "import time\n",
    "import math\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from numpy import nan as Nan\n",
    "from numpy import inf as inf\n",
    "from tqdm import notebook as tqdm\n",
    "from scipy.sparse import csr_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4a. Introduction\n",
    "With >25,000 structures and many different featurizers, we expect that there will be some incompatibilies. Some featurizer-structure combinations will return Nan, Null, or Inf values. It is important to consider that these erorrs will cause some feature representations to lose some of the labels. \n",
    "\n",
    "To compare the efficacy of agglomerative clustering between feature representations we need to ensure that the same labels are always used. This notebook does the following:\n",
    "\n",
    "1. Finds all rows (structures) in the structures_df where Nan, Null, or Inf values exist. \n",
    "2. Creates a boolean array for each feature represention to indicate which rows are valid. \n",
    "3. Merges all the boolean arrays to find a subset of structures that work for all the features. \n",
    "\n",
    "Finally, the notebook will save a sparse representation of each feature. This is done because some of the feature vectors are extremely large. Creating a sparse representation can speed up computations.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nan_and_inf_finder(features):\n",
    "    \"\"\"\n",
    "    Function to find the Nan, Null, or Inf values in the feature dataframe.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    features : np.array\n",
    "        A feature representation for each structure\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    lost_features_count : int\n",
    "        A count of all rows that contain errors. \n",
    "    \n",
    "    valid_features : np.array()\n",
    "        The index positions for the valid features\n",
    "    \"\"\"      \n",
    "    nan_array = np.isnan(features).any(1)\n",
    "    inf_array = np.isinf(features).any(1)\n",
    "    lost_features_count = np.logical_or(nan_array, inf_array).sum()\n",
    "    valid_features = np.logical_not(np.logical_or(nan_array, inf_array))\n",
    "    return lost_features_count, valid_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nan_and_inf_finder_SOAP(features):\n",
    "    \"\"\"\n",
    "    Function to find the Nan, Null, or Inf values in the SOAP feature represntation.\n",
    "    Because of SOAP's immense size, it is always saved as a sparse matrix. Thus this\n",
    "    function is required to specifically handle SOAP. \n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    features : scipy.sparse.csr.csr_matrix\n",
    "        A feature representation for each structure\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    lost_features_count : int\n",
    "        A count of all rows that contain errors. \n",
    "    \n",
    "    valid_features : np.array\n",
    "        The index positions for the valid features\n",
    "    \"\"\"     \n",
    "    if np.isnan(features.data).any() == False:\n",
    "        if np.isinf(features.data).any() == False:\n",
    "            lost_features_count = 0\n",
    "            valid_features = np.ones(np.shape(features)[0], dtype=bool)\n",
    "            return lost_features_count, valid_features\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_sparse_features(features, filename):\n",
    "    \"\"\"\n",
    "    Function to save a sparse feature representation for each feature. The files are saved with the same name\n",
    "    but in a new directory: 'saved_sparse_features'.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    features : np.array\n",
    "        A feature representation for each structure.\n",
    "        \n",
    "    filename: str\n",
    "        The original filename for the feature. \n",
    "    \"\"\" \n",
    "    sparse_features = csr_matrix(features)\n",
    "    \n",
    "    # save the sparse representation\n",
    "    save_path = os.path.join(os.getcwd(), 'sparse_features/{}.pkl'.format(filename))\n",
    "    save_file = open(save_path, 'wb')\n",
    "    pickle.dump(sparse_features, save_file)\n",
    "    save_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4b. Iterate over all the files in the saved_features directory\n",
    "1. Check for Nan, Null, or Inf values. \n",
    "2. Compile a list of valid structures across all features. \n",
    "3. Save a sparse representation of each feature in the saved_sparse_features directory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 rows are lost in the feature: scm_features_mode-structure.npy\n",
      "0 rows are lost in the feature: SOAP_features_partialS_outer_rcut-3_nmax-5_lmax-3_mode-structure_CAN.npy\n"
     ]
    }
   ],
   "source": [
    "valid_features_df = pd.DataFrame()\n",
    "files = os.listdir('features/')\n",
    "for file in files:\n",
    "\n",
    "    # remove the .npy extension\n",
    "    filename = file[0:-4]\n",
    "    if re.search('SOAP', file):\n",
    "        features = csr_matrix(np.load(io.BytesIO(open('features/{}'.format(file), 'rb').read()), allow_pickle=True).all())\n",
    "        lost_features_count, valid_features = nan_and_inf_finder_SOAP(features)\n",
    "        # save the sparse representation\n",
    "        save_path = os.path.join(os.getcwd(), 'sparse_features/{}.pkl'.format(filename))\n",
    "        save_file = open(save_path, 'wb')\n",
    "        pickle.dump(features, save_file)\n",
    "        save_file.close()\n",
    "        \n",
    "    elif re.search('ipynb_checkpoints', file):\n",
    "        next\n",
    "    else:\n",
    "        features = np.load('features/{}'.format(file), allow_pickle=True)\n",
    "        lost_features_count, valid_features = nan_and_inf_finder(features)\n",
    "        # create a sparse representation for each feature\n",
    "        save_sparse_features(features, filename)\n",
    "\n",
    "    valid_features_df[filename] = valid_features\n",
    "    print(\"{} rows are lost in the feature: {}\".format(lost_features_count, file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scm_features_mode-structure</th>\n",
       "      <th>SOAP_features_partialS_outer_rcut-3_nmax-5_lmax-3_mode-structure_CAN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   scm_features_mode-structure  \\\n",
       "0                         True   \n",
       "1                         True   \n",
       "2                         True   \n",
       "3                         True   \n",
       "4                         True   \n",
       "\n",
       "   SOAP_features_partialS_outer_rcut-3_nmax-5_lmax-3_mode-structure_CAN  \n",
       "0                                               True                     \n",
       "1                                               True                     \n",
       "2                                               True                     \n",
       "3                                               True                     \n",
       "4                                               True                     "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_features_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 rows will be lost because of Nan or Inf entries.\n"
     ]
    }
   ],
   "source": [
    "valid_features_df['compiled'] = valid_features_df.all(axis=1)\n",
    "print(\"{} rows will be lost because of Nan or Inf entries.\".format(len(valid_features_df)-valid_features_df.compiled.sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4c. Determine how many labels will be lost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After deleting the rows, 220/220 labels will remain in the dataset.\n"
     ]
    }
   ],
   "source": [
    "# open the labeled data file\n",
    "save_path = os.path.join(os.getcwd(), 'semi-supervised_supporting_files/labels_df.pkl')\n",
    "open_file = open(save_path, 'rb')\n",
    "labels_df = pickle.load(open_file)\n",
    "open_file.close()\n",
    "\n",
    "# grab the index positions for the labels\n",
    "idx_of_labels = labels_df[labels_df.conductivity>0].index\n",
    "\n",
    "# grab the index positions for rows without any feature errors\n",
    "idx_of_valid_features = valid_features_df[valid_features_df.compiled==True].index\n",
    "\n",
    "# list comprehension to find the indices that represent labels without having any feature errors\n",
    "idx_of_valid_labels = [x for x in idx_of_labels if x in idx_of_valid_features]\n",
    "print('After deleting the rows, {}/{} labels will remain in the dataset.'.format(len(idx_of_valid_labels), len(idx_of_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = os.path.join(os.getcwd(), 'semi-supervised_supporting_files/valid_features_df.pkl')\n",
    "save_file = open(save_path, 'wb')\n",
    "pickle.dump(valid_features_df, save_file)\n",
    "save_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
