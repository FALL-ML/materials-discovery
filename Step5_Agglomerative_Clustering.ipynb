{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import pickle\n",
    "# import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# from pymatgen.io import ase\n",
    "# from ase import atoms\n",
    "# from ase.io import read, write\n",
    "\n",
    "from tqdm import notebook as tqdm\n",
    "\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse import hstack\n",
    "# from sklearn.decomposition import IncrementalPCA\n",
    "\n",
    "from scipy.cluster.hierarchy import dendrogram\n",
    "from scipy.cluster.hierarchy import fcluster\n",
    "from scipy.cluster import hierarchy\n",
    "import scipy.spatial.distance as ssd\n",
    "from sklearn import metrics as skmetrics\n",
    "\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agglomerative_Clustering:\n",
    "    \"\"\"\n",
    "    A class to handle agglomerative clustering for each of the features. \n",
    "\n",
    "    ...\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    valid_features_df_path : str\n",
    "        The location of the valid_features_df.pkl file. \n",
    "    \n",
    "    labels_df_path : str\n",
    "        The location of the labels_df.pkl file. \n",
    "\n",
    "    saved_features_path : str\n",
    "        The directory where the sparse features are saved.\n",
    "        \n",
    "    results_df_path : str\n",
    "        The location where the results should be saved: results_df.pkl.  \n",
    "        \n",
    "    valid_features_df : pd.DataFrame\n",
    "        A dataframe that contains booleans indicating whether or not a structure-feature combination is error free. \n",
    "        \n",
    "    labels_df : pd.DataFrame\n",
    "        A dataframe containing the labeled data (i.e., conductivity and BVSE values). \n",
    "        \n",
    "    results_df : pd.DataFrame\n",
    "        A dataframe containing the results from the agglomerative clustering. \n",
    "        \n",
    "    feature_map : list\n",
    "        A list of all the feature files in the saved_features_path directory. These should be the sparse representations. \n",
    "\n",
    "    Methods\n",
    "    -------\n",
    "    list_features():\n",
    "        Set the mode that the class operates in. Each move corresponds to one of the nine structure representations. \n",
    "        \n",
    "    feature_merger(selection, multiplication_factor, valid_features_df, labels_df, feature_map, common_labels):\n",
    "        Takes the requested features, multiplies them by a given factor, and merges them together into a combined feature vector. \n",
    "        \n",
    "    distance_matrix_calculator(sparse_features):\n",
    "        Uses skmetrics.pairwise_distances_chunked to calculate the distance matrix on the sparse represenatation of the feature vector. \n",
    "    \n",
    "    augmented_dendrogram(*args, **kwargs):\n",
    "        A wrapper for scipy.cluster.hierarchy.dendrogram that allows for dendrogram customization. \n",
    "    \n",
    "    clustering(ddata, linkage_matrix, periods=2):\n",
    "        Applies scipy.cluster.hierarchy.fcluster to the linkage matrix to return the cluster labels for each level of clustering. \n",
    "    \n",
    "    conductivity_variance_calculation(valid_labels_df, cluster_sets):\n",
    "        Given the cluster assignment at each clustering level, the intracluster conductivity variance is calculated from the labels. \n",
    "    \n",
    "    bvse_variance_calculation(valid_labels_df, cluster_sets):\n",
    "        Given the cluster assignment at each clustering level, the intracluster BVSE variance is calculated from the labels. \n",
    "    \n",
    "    save_results(selection, multiplier, cluster_sets, conductivity_variance_by_cluster, bvse_variance_by_cluster, ddata, linkage_matrix):\n",
    "        Save the agglomerative clustering results in a pandas dataframe using pickle.\n",
    "    \n",
    "    run_clustering(feature_selector_list, multiplier_list, common_labels=True):\n",
    "        A wrapper which runs the entire agglomerative clustering routine using the methods above. \n",
    "        \n",
    "    \"\"\"\n",
    "    def __init__(self, valid_features_df_path, labels_df_path, saved_features_path, results_df_path):\n",
    "        self.valid_features_df_path = valid_features_df_path\n",
    "        self.labels_df_path = labels_df_path\n",
    "        self.saved_features_path = saved_features_path\n",
    "        self.results_df_path = results_df_path\n",
    "        \n",
    "        # load in the valid_features_df\n",
    "        open_file = open(self.valid_features_df_path, 'rb')\n",
    "        self.valid_features_df = pickle.load(open_file)\n",
    "        open_file.close()\n",
    "\n",
    "        # load in the labels_df\n",
    "        open_file = open(self.labels_df_path, 'rb')\n",
    "        self.labels_df = pickle.load(open_file)\n",
    "        open_file.close()\n",
    "        \n",
    "        # grab all features from the repository\n",
    "        self.feature_map = []\n",
    "        files = os.listdir(self.saved_features_path)\n",
    "        for file in files:\n",
    "            self.feature_map.append(file)\n",
    "        \n",
    "        # either create a fresh results_df or load one ine\n",
    "        try:\n",
    "            # load in the results_df\n",
    "            open_file = open(self.results_df_path, 'rb')\n",
    "            self.results_df = pickle.load(open_file)\n",
    "            open_file.close()\n",
    "        except:\n",
    "            self.results_df = pd.DataFrame(columns=['feature0', 'multiplier0', 'feature1', 'multiplier1', 'conductivity_variance', 'bvse_variance', 'cluster_sets', 'ddata', 'linkage_matrix'])\n",
    "\n",
    "    def list_features(self):\n",
    "        \"\"\"\n",
    "        Prints feature_map attribute with the associated indices. \n",
    "        This allows the user to choose which features will be used. \n",
    "        \"\"\"      \n",
    "        for idx, feature in enumerate(self.feature_map):\n",
    "            print(\"{} - {}\".format(idx, feature[0:-4]))\n",
    "            \n",
    "   \n",
    "    def feature_merger(self, selection, multiplication_factor, valid_features_df, labels_df, feature_map, common_labels = True):\n",
    "        \"\"\"\n",
    "        The function takes a 1D list of selected features and a 1D list of multiplication factors. Each feature\n",
    "        is multiplied by the corresponding entry in the multiplication list. The multiplied features are then merged to \n",
    "        form a composite feature vector. A sparse representation is returned. \n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        selection : list,1D\n",
    "            A list of the features that will be merged. The list should be of the form: [x] or [x, y].\n",
    "            The former representation simply returns the feature x.\n",
    "            The latter representation would combine features x and y togther to make a composite feature vector.  \n",
    "            The numbers are mapped to their feature through the feature_map list (described below). \n",
    "\n",
    "        multiplication_factor : list,1D\n",
    "            A list of multipliers that will be applied to the selected features. This allows the features\n",
    "            to be mixed in different ratios.  \n",
    "\n",
    "        valid_features_df : pd.DataFrame\n",
    "            The pandas dataframe containing boolean entries for all feature-structure combinations. And also\n",
    "            a final column that is the logical.AND of all the columns (i.e., the structures that will work\n",
    "            for every single feature representation). \n",
    "\n",
    "        feature_map : list\n",
    "            The list of sparse features saved in the feature directory. The function uses this to map\n",
    "            the numeric selections into the desired features. \n",
    "\n",
    "        common_labels : boolean\n",
    "            If true, then the structures that are safe for all features representations will be used. \n",
    "            If false, then the structures that are safe only for the supplied features (in the selection list)\n",
    "            will be used. \n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        sparse_features : scipy.sparse.csr.csr_matrix\n",
    "            The combined features of interest in a sparse matrix. \n",
    "\n",
    "        valid_labels_df : pd.DataFrame\n",
    "            A dataframe only containing the rows that are valid for the feature representation. \n",
    "        \"\"\"      \n",
    "        sparse_features = []\n",
    "        feature_names = []\n",
    "        for idx, feature_number in enumerate(tqdm.tqdm(selection, desc='Merging Features')):\n",
    "            feature_path = feature_map[feature_number]\n",
    "            feature_names.append(feature_path[0:-4])\n",
    "            save_path = '{}{}'.format(self.saved_features_path, feature_path)\n",
    "            open_file = open(save_path, 'rb')\n",
    "            temp_instance = pickle.load(open_file)\n",
    "            open_file.close()\n",
    "            sparse_features.append(temp_instance*multiplication_factor[idx])\n",
    "\n",
    "        if common_labels:\n",
    "            valid_rows = valid_features_df.compiled\n",
    "        else: \n",
    "            valid_rows = valid_features_df.loc[:, feature_names].all(axis=1)\n",
    "\n",
    "        sparse_features = hstack(sparse_features, format='csr')[valid_rows]\n",
    "        valid_labels_df = labels_df.loc[valid_rows, :].copy()\n",
    "\n",
    "        return sparse_features, valid_labels_df\n",
    "    \n",
    "    \n",
    "    def distance_matrix_calculator(self, sparse_features):\n",
    "        \"\"\"\n",
    "        Function to take the sparse features and calculate the distance matrix. The distance matrix\n",
    "        can be used to construct the agglomerative clustering representation. \n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        sparse_features : scipy.sparse.csr.csr_matrix\n",
    "            The combined features of interest in a sparse matrix. \n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        ssd.squareform(distance_matrix) : np.array\n",
    "            The squareform of the distance matrix. \n",
    "            \"\"\"      \n",
    "        distance = skmetrics.pairwise_distances_chunked(sparse_features, n_jobs=63, working_memory=1000)\n",
    "        distance_matrix = next(distance)\n",
    "\n",
    "        while True:\n",
    "            try:\n",
    "                distance_matrix = np.concatenate((distance_matrix, next(distance)), axis=0)\n",
    "            except StopIteration:\n",
    "                break  # Iterator exhausted: stop the loop\n",
    "\n",
    "        distance_matrix = (distance_matrix+distance_matrix.T)/2\n",
    "        return ssd.squareform(distance_matrix)\n",
    "    \n",
    "    \n",
    "    def augmented_dendrogram(self, *args, **kwargs):\n",
    "        \"\"\"\n",
    "        A wrapper for the scipy.cluster.hierarchy.dendrogram method. The dendrogram method is used to \n",
    "        construct the agglomerative dendrogram after applying the scipy.cluster.hierarchy.linkage method to the distance matrix. \n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        ddata : np.array\n",
    "            The agglomerative dendrogram found by applying the scipy.cluster.hierarchy.dendrogram\n",
    "            method to the linkage matrix.\n",
    "        \"\"\" \n",
    "        max_d = kwargs.pop('max_d', None)\n",
    "        if max_d and 'color_threshold' not in kwargs:\n",
    "            kwargs['color_threshold'] = max_d\n",
    "        annotate_above = kwargs.pop('annotate_above', 0)\n",
    "\n",
    "        ddata = dendrogram(*args, **kwargs)\n",
    "\n",
    "        if not kwargs.get('no_plot', False):\n",
    "            plt.title('Hierarchical Clustering Dendrogram (truncated)')\n",
    "            plt.xlabel('sample index or (cluster size)')\n",
    "            plt.ylabel('distance')\n",
    "            for i, d, c in zip(ddata['icoord'], ddata['dcoord'], ddata['color_list']):\n",
    "                x = 0.5 * sum(i[1:3])\n",
    "                y = d[1]\n",
    "                if y > annotate_above:\n",
    "                    plt.plot(x, y, 'o', c=c)\n",
    "            if max_d:\n",
    "                plt.axhline(y=max_d, c='k')\n",
    "        return ddata\n",
    "    \n",
    "    \n",
    "    def clustering(self, ddata, linkage_matrix, periods=2):\n",
    "        \"\"\"\n",
    "        The function uses the agglomerative dendrogram and the linkage matrix to determine which structures are labeled\n",
    "        with which clusters at each level of clustering. \n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        ddata : np.array\n",
    "            The agglomerative dendrogram found by applying the scipy.cluster.hierarchy.dendrogram\n",
    "            method to the linkage matrix.\n",
    "\n",
    "        linkage_matrix : np.array\n",
    "            The linkage matrix found by applying the scipy.cluster.hierarchy.linkage method to\n",
    "            the distance matrix. \n",
    "\n",
    "        periods : int\n",
    "            Used to calculate the midpoint positions in the agglomerative dendrogram. Should be set \n",
    "            to 2 for branches that split in two. \n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        cluster_sets : np.array\n",
    "            The assignment of each structure to a cluster, for each level of clustering. \n",
    "        \"\"\"\n",
    "        dcoord = np.array(ddata['dcoord'])\n",
    "        offset_points = np.sort(dcoord[:,1])[::-1]\n",
    "        weights = np.ones(periods) / periods\n",
    "        average_midpoints =  np.convolve(offset_points, weights, mode='valid')\n",
    "\n",
    "        # create an initial row where everything is in cluster #1\n",
    "        cluster_sets = [np.ones(np.shape(linkage_matrix)[0]+1, dtype=np.int32)]\n",
    "\n",
    "        for max_d in average_midpoints:\n",
    "            clusters = fcluster(linkage_matrix, max_d, criterion='distance')\n",
    "            cluster_sets.append(clusters)\n",
    "\n",
    "        cluster_sets = np.array(cluster_sets)\n",
    "\n",
    "        return cluster_sets\n",
    "    \n",
    "    \n",
    "    def conductivity_variance_calculation(self, valid_labels_df, cluster_sets): \n",
    "        \"\"\"\n",
    "        Given the assignment of labeled structures into each cluster, this method\n",
    "        calculates the intracluster conductivity variance. The calculation is done \n",
    "        for each level of clustering. A frozen state strategy is used:\n",
    "        (1) calculations start at the lowest level of clustering (i.e. 2 clusters)\n",
    "        (2) at each level the partial variance is calculated for each label and then saved in a 'current_state' column\n",
    "        (3) the partial variances will be summed to give the total intracluster variance\n",
    "        (4) however, before summation, the labels are examined to see if any have been sorted into a cluster by themselves\n",
    "            (i.e. without any other labels).\n",
    "        (5) labels sorted by themselves would result in 0 partial variance. Instead, these labels are reverted to the \n",
    "            'previous_state' which is just the 'current_state' column from the previous clustering level\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        valid_labels_df : pd.DataFrame\n",
    "            A dataframe only containing the rows that are valid for the feature representation.\n",
    "\n",
    "        cluster_sets : np.array\n",
    "            The assignment of each structure to a cluster, for each level of clustering. \n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        variance_by_cluster : np.array\n",
    "            The intracluster conductivity variance at each level of clustering. \n",
    "        \"\"\"\n",
    "        # create four new columns in the dataframe\n",
    "        valid_labels_df['log_conductivity'] = None\n",
    "        valid_labels_df['partial_variance'] = 0\n",
    "        valid_labels_df['partial_variance_previous_state'] = 0\n",
    "        valid_labels_df['cluster'] = 0\n",
    "\n",
    "        # take the log10 conductivity and populate the 'log_conductivity' column\n",
    "        mask = valid_labels_df['conductivity']>0\n",
    "        temp_df = valid_labels_df.loc[mask, 'conductivity']\n",
    "        valid_labels_df.loc[mask, 'log_conductivity'] = temp_df.apply(lambda x: np.log10(x))\n",
    "\n",
    "        # make a list to store the calculations in\n",
    "        variance_by_cluster = []\n",
    "\n",
    "        # iterate through the clustering sets, starting at 1 cluster\n",
    "        for cluster_set in tqdm.tqdm(cluster_sets, desc='Calculating Conductivity Variance'):\n",
    "            # label all the rows with their cluster\n",
    "            valid_labels_df['cluster'] = cluster_set\n",
    "\n",
    "            # groupby method to count the number of labels in each cluster\n",
    "            cluster_counts = valid_labels_df.groupby('cluster').count()['conductivity']\n",
    "\n",
    "            # groupby method to determine the log_conductivity mean for each cluster\n",
    "            cluster_means = valid_labels_df.groupby('cluster')['log_conductivity'].mean()\n",
    "\n",
    "             # helper function for calculating the partial variance. Used by pd.DataFrame.apply() in the variance_calculation function\n",
    "            def partial_variance_helper(row, cluster_means, cluster_counts):\n",
    "                return (row['log_conductivity']-cluster_means[row['cluster']])**2\n",
    "\n",
    "            # calculate the partial variance for each row with a conductivity value\n",
    "            mask = valid_labels_df['conductivity']>0\n",
    "            temp_df = valid_labels_df[mask]\n",
    "            valid_labels_df.loc[mask, 'partial_variance'] = temp_df.apply(partial_variance_helper,  axis=1, args=([cluster_means, cluster_counts]))\n",
    "\n",
    "            # create a dataframe just with the variance labels\n",
    "            variance_df = valid_labels_df[valid_labels_df['conductivity']>0].loc[:, ['cluster', 'partial_variance']]\n",
    "\n",
    "            # group the variance_df by cluster\n",
    "            cluster_grouping = variance_df.groupby('cluster')\n",
    "\n",
    "            # find the clusters that contain <=1 label. These are the frozen clusters. Return the index for the labels in the frozen clusters. \n",
    "            frozen_groups = variance_df.groupby('cluster').count()[(variance_df.groupby('cluster').count()<=1).values]\n",
    "            frozen_idx = [idx for sublist in [cluster_grouping.groups[x].values.tolist() for x in frozen_groups.index.values] for idx in sublist]\n",
    "\n",
    "            # return all frozen rows to their previous value\n",
    "            valid_labels_df.loc[frozen_idx, 'partial_variance'] = valid_labels_df.loc[frozen_idx, 'partial_variance_previous_state']\n",
    "\n",
    "            # calculate the intracluster conductivity variance. This is just the sum of the partial variance column\n",
    "            variance_by_cluster.append(valid_labels_df.partial_variance.sum())\n",
    "\n",
    "            # update the frozen state before moving to the next iteration\n",
    "            valid_labels_df.loc[:, 'partial_variance_previous_state'] = valid_labels_df.loc[:, 'partial_variance']\n",
    "\n",
    "        return variance_by_cluster\n",
    "\n",
    "    \n",
    "    def bvse_variance_calculation(self, valid_labels_df, cluster_sets):\n",
    "        \"\"\"\n",
    "        Given the assignment of labeled structures into each cluster, this method\n",
    "        calculates the intracluster bvse variance. The calculation is done \n",
    "        for each level of clustering. A frozen state strategy is used:\n",
    "        (1) calculations start at the lowest level of clustering (i.e. 2 clusters)\n",
    "        (2) at each level the partial variance is calculated for each label and then saved in a 'current_state' column\n",
    "        (3) the partial variances will be summed to give the total intracluster variance\n",
    "        (4) however, before summation, the labels are examined to see if any have been sorted into a cluster by themselves\n",
    "            (i.e. without any other labels).\n",
    "        (5) labels sorted by themselves would result in 0 partial variance. Instead, these labels are reverted to the \n",
    "            'previous_state' which is just the 'current_state' column from the previous clustering level\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        valid_labels_df : pd.DataFrame\n",
    "            A dataframe only containing the rows that are valid for the feature representation.\n",
    "\n",
    "        cluster_sets : np.array\n",
    "            The assignment of each structure to a cluster, for each level of clustering. \n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        variance_by_cluster : np.array\n",
    "            The intracluster bvse variance at each level of clustering. \n",
    "        \"\"\"\n",
    "        # create four new columns in the dataframe\n",
    "        valid_labels_df['partial_variance'] = 0\n",
    "        valid_labels_df['partial_variance_previous_state'] = 0\n",
    "        valid_labels_df['cluster'] = 0\n",
    "\n",
    "        # make a list to store the calculations in\n",
    "        variance_by_cluster = []\n",
    "\n",
    "        # iterate through the clustering sets, starting at 1 cluster\n",
    "        for cluster_set in tqdm.tqdm(cluster_sets, desc='Calculating BVSE Variance'):\n",
    "            # label all the rows with their cluster\n",
    "            valid_labels_df['cluster'] = cluster_set\n",
    "\n",
    "            # groupby method to count the number of labels in each cluster\n",
    "            cluster_counts = valid_labels_df.groupby('cluster').count()['BVSE']\n",
    "\n",
    "            # groupby method to determine the BVSE mean for each cluster\n",
    "            cluster_means = valid_labels_df.groupby('cluster')['BVSE'].mean()\n",
    "\n",
    "             # helper function for calculating the partial variance. Used by pd.DataFrame.apply() in the variance_calculation function\n",
    "            def partial_variance_helper(row, cluster_means, cluster_counts):\n",
    "                return (row['BVSE']-cluster_means[row['cluster']])**2\n",
    "\n",
    "            # calculate the partial variance for each row with a BVSE value\n",
    "            mask = valid_labels_df['BVSE']>0\n",
    "            temp_df = valid_labels_df[mask]\n",
    "            valid_labels_df.loc[mask, 'partial_variance'] = temp_df.apply(partial_variance_helper,  axis=1, args=([cluster_means, cluster_counts]))\n",
    "\n",
    "            # create a dataframe just with the variance labels\n",
    "            variance_df = valid_labels_df[valid_labels_df['BVSE']>0].loc[:, ['cluster', 'partial_variance']]\n",
    "\n",
    "            # group the variance_df by cluster\n",
    "            cluster_grouping = variance_df.groupby('cluster')\n",
    "\n",
    "            # find the clusters that contain <=1 label. These are the frozen clusters. Return the index for the labels in the frozen clusters. \n",
    "            frozen_groups = variance_df.groupby('cluster').count()[(variance_df.groupby('cluster').count()<=1).values]\n",
    "            frozen_idx = [idx for sublist in [cluster_grouping.groups[x].values.tolist() for x in frozen_groups.index.values] for idx in sublist]\n",
    "\n",
    "            # return all frozen rows to their previous value\n",
    "            valid_labels_df.loc[frozen_idx, 'partial_variance'] = valid_labels_df.loc[frozen_idx, 'partial_variance_previous_state']\n",
    "\n",
    "            # calculate the intracluster BVSE variance. This is just the sum of the partial variance column\n",
    "            variance_by_cluster.append(valid_labels_df.partial_variance.sum())\n",
    "\n",
    "            # update the frozen state before moving to the next iteration\n",
    "            valid_labels_df.loc[:, 'partial_variance_previous_state'] = valid_labels_df.loc[:, 'partial_variance']\n",
    "\n",
    "        return variance_by_cluster\n",
    "    \n",
    "    \n",
    "    def save_results(self, selection, multiplier, cluster_sets, conductivity_variance_by_cluster, bvse_variance_by_cluster, ddata, linkage_matrix):\n",
    "        \"\"\"\n",
    "        The function saves all the relevant outputs from the agglomerative clustering process \n",
    "        in a pandas dataframe using pickle. Save the pickled dataframe at the self.results_df_path attribute. \n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        selection : list\n",
    "            The feature(s) that were combined. \n",
    "            \n",
    "        selection : list\n",
    "            The multiplication factor for each feature in the selection.  \n",
    "\n",
    "        cluster_sets : np.array\n",
    "            The assignment of each structure to a cluster, for each level of clustering. \n",
    "\n",
    "        conductivity_variance_by_cluster : np.array\n",
    "            The intracluster conductivity variance at each level of clustering. \n",
    "            \n",
    "        bvse_variance_by_cluster : np.array\n",
    "            The intracluster bvse variance at each level of clustering. \n",
    "       \n",
    "        ddata : np.array\n",
    "            The agglomerative dendrogram found by applying the scipy.cluster.hierarchy.dendrogram\n",
    "            method to the linkage matrix.\n",
    "\n",
    "        linkage_matrix : np.array\n",
    "            The linkage matrix found by applying the scipy.cluster.hierarchy.linkage method to\n",
    "            the distance matrix. \n",
    "        \"\"\"\n",
    "        if len(self.results_df)==0:\n",
    "            new_row_idx = 0\n",
    "        else:\n",
    "            new_row_idx = self.results_df.index.max()+1\n",
    "\n",
    "        for idx, feature in enumerate(selection):\n",
    "            self.results_df.at[new_row_idx, 'feature{}'.format(idx)] = self.feature_map[feature][0:-4]\n",
    "\n",
    "        for idx, multiple in enumerate(multiplier):\n",
    "            self.results_df.at[new_row_idx, 'multiplier{}'.format(idx)] = multiple\n",
    "\n",
    "        self.results_df.at[new_row_idx, 'conductivity_variance'] = conductivity_variance_by_cluster\n",
    "        self.results_df.at[new_row_idx, 'bvse_variance'] = bvse_variance_by_cluster\n",
    "        self.results_df.at[new_row_idx, 'cluster_sets'] = cluster_sets\n",
    "        self.results_df.at[new_row_idx, 'ddata'] = ddata\n",
    "        self.results_df.at[new_row_idx, 'linkage_matrix'] = linkage_matrix\n",
    "        \n",
    "        save_path = os.path.join(os.getcwd(), self.results_df_path)\n",
    "        save_file = open(save_path, 'wb')\n",
    "        pickle.dump(self.results_df, save_file)\n",
    "        save_file.close()\n",
    "    \n",
    "   \n",
    "    def run_clustering(self, feature_selector_list, multiplier_list, common_labels=True):\n",
    "        \"\"\"\n",
    "        A wrapper to run through the entire agglomerative clustering process, by calling the methods above.\n",
    "        The function takes a 2D list of desired features and a 2D list of multiplication factors. For each zipped pair in the list \n",
    "        the features are multiplied by the multiplication factors and then merged. \n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        feature_selctor_list : list,2D\n",
    "            A list of the features that will be merged. The list should be of the form: [[1,2], [1,3]] or [[1], [2], [3]].\n",
    "            The former representation would combine features 1&2 during the first iteration and then 1&3 in\n",
    "            the next iteration. The latter representation will simply return the features 1, 2, and 3 sequentially. \n",
    "            The numbers are mapped to their feature through the feature_map list. \n",
    "\n",
    "        multiplier_list : list,2D\n",
    "            A list of multipliers that will be applied to the selected features. This allows the features\n",
    "            to be mixed in different ratios.  \n",
    "\n",
    "        common_labels : boolean\n",
    "            If true, then the structures that are safe for all features representations will be used. \n",
    "            If false, then the structures that are safe only for the supplied features (in the feature selector list)\n",
    "            will be used. \n",
    "        \"\"\"\n",
    "        for selection, multiplier in tqdm.tqdm(zip(feature_selector_list, multiplier_list), desc='Iterating Through Selections', total=len(feature_selector_list)):\n",
    "            print('-' * 50)\n",
    "            print('\\033[1mWorking on selection = {}\\033[0m'.format(selection))\n",
    "            sparse_features, valid_labels_df = self.feature_merger(selection, multiplier, self.valid_features_df, self.labels_df, self.feature_map, common_labels=common_labels)\n",
    "            distance_matrix = self.distance_matrix_calculator(sparse_features)\n",
    "            linkage_matrix = hierarchy.linkage(distance_matrix, 'ward')\n",
    "            \n",
    "            max_clustering = 300\n",
    "            ddata = self.augmented_dendrogram(\n",
    "                linkage_matrix,\n",
    "                truncate_mode='lastp',\n",
    "                p=max_clustering+1,\n",
    "                leaf_rotation=90.,\n",
    "                leaf_font_size=3.,\n",
    "                show_contracted=False,\n",
    "                annotate_above=5,  # useful in small plots so annotations don't overlap\n",
    "                max_d=50, #where this is the distance cutoff\n",
    "                above_threshold_color='grey',\n",
    "                no_plot = True\n",
    "            )\n",
    "\n",
    "            cluster_sets = self.clustering(ddata, linkage_matrix)\n",
    "            conductivity_variance_by_cluster = self.conductivity_variance_calculation(valid_labels_df, cluster_sets)\n",
    "            bvse_variance_by_cluster = self.bvse_variance_calculation(valid_labels_df, cluster_sets)\n",
    "\n",
    "            self.save_results(selection, multiplier, cluster_sets, conductivity_variance_by_cluster, bvse_variance_by_cluster, ddata, linkage_matrix)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5a. Instantiate the Agglomerative_Clustering class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ag = Agglomerative_Clustering(valid_features_df_path = 'valid_features_df.pkl', labels_df_path = 'labeled_data_BVSE.pkl', saved_features_path = 'saved_sparse_features/', results_df_path='ac_results_df.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5b. List the features in the saved directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 - ape_features_mode-structure_CAMN\n",
      "1 - density_features_mode-structure_CAMN\n",
      "2 - bc_features_mode-structure_CAMN\n",
      "3 - SOAP_features_partialS_outer_rcut-8_nmax-10_lmax-9_mode-structure_CAMN\n",
      "4 - rdf_features_cutoff-10_binsize-0.1_mode-structure_CAMN\n",
      "5 - xrd_features_pattern_length-451_mode-structure_CAMN\n",
      "6 - os_features_mode-structure_CAMN\n"
     ]
    }
   ],
   "source": [
    "ag.list_features()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 5c. Feed a 2D list of features (by index) and multipliers for agglomerative clustering\n",
    "The class can work either on single features or by combining features with a mixing ratio. \n",
    "For single features, the lists should be of the forms:\n",
    "* feature_selector_list = [[x], [y], [z]]\n",
    "* multiplier_list = [[1], [1], [1]]\n",
    "\n",
    "This notation will apply agglomerative clustering to each supplied feature, seperately. An agglomerative clustering output will be saved for x, then y, then z. The multiplier value doesn't actually matter when only one feature is used.  \n",
    "\n",
    "For combined feature vectors, the lists should be of the forms:\n",
    "* feature_selector_list = [[x1,x2], [y1,y2], [z1,z2]]\n",
    "* multiplier_list = [[a1,a2], [b1,b2], [c1,c2]]\n",
    "\n",
    "In the example notation, agglomerative clustering will be applied three times on the following compositive feature vectors:\n",
    "* a1(x1) concatenated with a2(x2)\n",
    "* b1(y1) concatenated with b2(y2)\n",
    "* c1(z1) concatenated with c2(z2)\n",
    "\n",
    "__!!!WARNING!!!__ Addition of new features to the saved_features_path will likely change the valid features. This is true because new features may cause different structures to throw errors when the featurize is applied. If the valid features change after a new feature is added then previous conductivity or BVSE variance calculations cannot be directly compared to any new conductivity or bvse variance calculations.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09983a29f3d3410eab7ef3e368a67790",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iterating Through Selections:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "\u001b[1mWorking on selection = [0, 1]\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "613b9505d5a44b268b9d712c3a96daa3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Merging Features:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6f341132f354d2ba6db732d280022cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating Conductivity Variance:   0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "683665409823417fa856b7e334109b8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating BVSE Variance:   0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "\u001b[1mWorking on selection = [5, 6]\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b00a0b5fbe0149cf9d5ce442f397151d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Merging Features:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30851ad0cd0442d895953f5653900346",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating Conductivity Variance:   0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d1f47482987464ab422b52f6733747d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating BVSE Variance:   0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ag.run_clustering(feature_selector_list=[[0,1],[5,6]], multiplier_list=[[1,3],[1,2]], common_labels=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature0</th>\n",
       "      <th>multiplier0</th>\n",
       "      <th>feature1</th>\n",
       "      <th>multiplier1</th>\n",
       "      <th>conductivity_variance</th>\n",
       "      <th>bvse_variance</th>\n",
       "      <th>cluster_sets</th>\n",
       "      <th>ddata</th>\n",
       "      <th>linkage_matrix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ape_features_mode-structure_CAMN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[2185.983729796786, 2148.6226659824033, 2148.6...</td>\n",
       "      <td>[52634.77398885612, 52288.47928676296, 52288.4...</td>\n",
       "      <td>[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,...</td>\n",
       "      <td>{'icoord': [[5.0, 5.0, 15.0, 15.0], [35.0, 35....</td>\n",
       "      <td>[[0.0, 4.0, 0.0, 2.0], [1.0, 3.0, 0.0, 2.0], [...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rdf_features_cutoff-10_binsize-0.1_mode-struct...</td>\n",
       "      <td>1</td>\n",
       "      <td>xrd_features_pattern_length-451_mode-structure...</td>\n",
       "      <td>2</td>\n",
       "      <td>[2185.983729796786, 2185.983729796786, 2185.98...</td>\n",
       "      <td>[52634.77398885612, 52634.77385616511, 52634.7...</td>\n",
       "      <td>[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,...</td>\n",
       "      <td>{'icoord': [[5.0, 5.0, 15.0, 15.0], [45.0, 45....</td>\n",
       "      <td>[[18771.0, 20718.0, 0.0, 2.0], [20837.0, 23805...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ape_features_mode-structure_CAMN</td>\n",
       "      <td>1</td>\n",
       "      <td>density_features_mode-structure_CAMN</td>\n",
       "      <td>3</td>\n",
       "      <td>[2185.983729796786, 2185.983729796786, 2185.98...</td>\n",
       "      <td>[52634.77398885612, 52634.77398885612, 52634.7...</td>\n",
       "      <td>[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,...</td>\n",
       "      <td>{'icoord': [[5.0, 5.0, 15.0, 15.0], [25.0, 25....</td>\n",
       "      <td>[[17788.0, 20343.0, 0.0, 2.0], [22597.0, 23809...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>xrd_features_pattern_length-451_mode-structure...</td>\n",
       "      <td>1</td>\n",
       "      <td>os_features_mode-structure_CAMN</td>\n",
       "      <td>2</td>\n",
       "      <td>[2185.983729796786, 2185.983729796786, 2176.13...</td>\n",
       "      <td>[52634.77398885612, 52634.77398885612, 52324.9...</td>\n",
       "      <td>[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,...</td>\n",
       "      <td>{'icoord': [[5.0, 5.0, 15.0, 15.0], [45.0, 45....</td>\n",
       "      <td>[[23381.0, 24462.0, 0.0, 2.0], [22912.0, 23575...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ape_features_mode-structure_CAMN</td>\n",
       "      <td>1</td>\n",
       "      <td>density_features_mode-structure_CAMN</td>\n",
       "      <td>3</td>\n",
       "      <td>[2185.983729796786, 2185.983729796786, 2185.98...</td>\n",
       "      <td>[52634.77398885612, 52634.77398885612, 52634.7...</td>\n",
       "      <td>[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,...</td>\n",
       "      <td>{'icoord': [[5.0, 5.0, 15.0, 15.0], [25.0, 25....</td>\n",
       "      <td>[[17788.0, 20343.0, 0.0, 2.0], [22597.0, 23809...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            feature0 multiplier0  \\\n",
       "0                   ape_features_mode-structure_CAMN           1   \n",
       "1  rdf_features_cutoff-10_binsize-0.1_mode-struct...           1   \n",
       "2                   ape_features_mode-structure_CAMN           1   \n",
       "3  xrd_features_pattern_length-451_mode-structure...           1   \n",
       "4                   ape_features_mode-structure_CAMN           1   \n",
       "\n",
       "                                            feature1 multiplier1  \\\n",
       "0                                                NaN         NaN   \n",
       "1  xrd_features_pattern_length-451_mode-structure...           2   \n",
       "2               density_features_mode-structure_CAMN           3   \n",
       "3                    os_features_mode-structure_CAMN           2   \n",
       "4               density_features_mode-structure_CAMN           3   \n",
       "\n",
       "                               conductivity_variance  \\\n",
       "0  [2185.983729796786, 2148.6226659824033, 2148.6...   \n",
       "1  [2185.983729796786, 2185.983729796786, 2185.98...   \n",
       "2  [2185.983729796786, 2185.983729796786, 2185.98...   \n",
       "3  [2185.983729796786, 2185.983729796786, 2176.13...   \n",
       "4  [2185.983729796786, 2185.983729796786, 2185.98...   \n",
       "\n",
       "                                       bvse_variance  \\\n",
       "0  [52634.77398885612, 52288.47928676296, 52288.4...   \n",
       "1  [52634.77398885612, 52634.77385616511, 52634.7...   \n",
       "2  [52634.77398885612, 52634.77398885612, 52634.7...   \n",
       "3  [52634.77398885612, 52634.77398885612, 52324.9...   \n",
       "4  [52634.77398885612, 52634.77398885612, 52634.7...   \n",
       "\n",
       "                                        cluster_sets  \\\n",
       "0  [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,...   \n",
       "1  [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,...   \n",
       "2  [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,...   \n",
       "3  [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,...   \n",
       "4  [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,...   \n",
       "\n",
       "                                               ddata  \\\n",
       "0  {'icoord': [[5.0, 5.0, 15.0, 15.0], [35.0, 35....   \n",
       "1  {'icoord': [[5.0, 5.0, 15.0, 15.0], [45.0, 45....   \n",
       "2  {'icoord': [[5.0, 5.0, 15.0, 15.0], [25.0, 25....   \n",
       "3  {'icoord': [[5.0, 5.0, 15.0, 15.0], [45.0, 45....   \n",
       "4  {'icoord': [[5.0, 5.0, 15.0, 15.0], [25.0, 25....   \n",
       "\n",
       "                                      linkage_matrix  \n",
       "0  [[0.0, 4.0, 0.0, 2.0], [1.0, 3.0, 0.0, 2.0], [...  \n",
       "1  [[18771.0, 20718.0, 0.0, 2.0], [20837.0, 23805...  \n",
       "2  [[17788.0, 20343.0, 0.0, 2.0], [22597.0, 23809...  \n",
       "3  [[23381.0, 24462.0, 0.0, 2.0], [22912.0, 23575...  \n",
       "4  [[17788.0, 20343.0, 0.0, 2.0], [22597.0, 23809...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ag.results_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
